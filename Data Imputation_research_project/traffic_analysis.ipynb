{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from sklearn.impute import KNNImputer\n",
    "import array\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions here\n",
    "\n",
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of               DateTime  Sensor_Data   Feature_1  Feature_2  Actual_Data\n",
      "0        3/1/2020 0:00     104762.9   7015629.8   421212.0     104762.9\n",
      "1        3/1/2020 1:00      72617.5   4851091.0   421212.0      72617.5\n",
      "2        3/1/2020 2:00      58848.7   3920233.0   421212.0      58848.7\n",
      "3        3/1/2020 3:00      47502.0   3157263.3   420162.0      47502.0\n",
      "4        3/1/2020 4:00      49846.5   3310866.3   421356.0      49846.5\n",
      "...                ...          ...         ...        ...          ...\n",
      "17838   3/14/2022 9:00     360370.0  20859266.4   433109.0     360370.0\n",
      "17839  3/14/2022 10:00     347459.2  20559468.4   433107.0     347459.2\n",
      "17840  3/14/2022 11:00     352971.4  20977783.1   433088.0     352971.4\n",
      "17841  3/14/2022 12:00     365768.4  21746139.2   433094.0     365768.4\n",
      "17842  3/14/2022 13:00     381860.3  22585788.6   433126.0     381860.3\n",
      "\n",
      "[17843 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Load csv and print header and values\n",
    "\n",
    "df = pd.read_csv('pems_output_traffic.csv',header=0)\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "<ipython-input-27-aba0b3d22ff1>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_simplified[\"Hour_of_Day\"] = pd.to_numeric(df_simplified[\"Hour_of_Day\"]) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_Id           1         2         3         4         5         6    \\\n",
      "Hour_of_Day                                                               \n",
      "1            104762.9   66557.1   64251.5   67052.3   67830.3   74698.3   \n",
      "2             72617.5   48130.1   49428.7   50760.9   50794.8   56439.5   \n",
      "3             58848.7   45861.2   48335.6   49227.7   49410.7   53745.0   \n",
      "4             47502.0   64646.9   66031.9   66244.3   66767.3   67945.3   \n",
      "5             49846.5  131846.0  129226.5  129319.5  129621.6  125050.8   \n",
      "6             68021.5  245473.4  237344.8  237794.1  238277.5  226017.3   \n",
      "7            104956.3  375336.7  387097.9  388905.2  387899.9  357099.0   \n",
      "8            145198.9  490284.0  507476.5  504289.7  502405.5  450309.8   \n",
      "9            200717.5  478898.4  501262.3  491585.1  487870.6  431999.1   \n",
      "10           271009.6  402896.5  420949.4  410417.5  413325.5  387257.4   \n",
      "11           329729.8  367241.9  368295.8  365810.4  374093.9  380276.2   \n",
      "12           365612.7  359576.9  353188.3  356740.7  370030.2  394238.3   \n",
      "13           390616.2  366849.2  362787.0  366784.2  378460.8  421637.2   \n",
      "14           401369.7  382037.7  381005.6  387427.9  402621.7  451920.7   \n",
      "15           403919.9  424833.3  433750.9  436464.2  456378.3  500235.2   \n",
      "16           397423.3  481876.0  495932.8  495341.2  515622.1  549755.9   \n",
      "17           384264.2  509861.6  531021.0  528981.2  550199.6  563311.6   \n",
      "18           367478.6  508180.0  540081.4  528595.8  556812.2  545033.1   \n",
      "19           339197.8  409399.4  442363.7  439855.1  460815.4  452540.5   \n",
      "20           296134.8  294219.1  311864.3  312981.1  333173.5  350323.3   \n",
      "21           257053.2  220690.6  230082.8  235918.3  255146.6  276881.4   \n",
      "22           203004.0  178661.7  188695.5  192792.2  208788.6  233617.5   \n",
      "23           149819.2  135806.2  146426.7  144612.8  159605.5  193884.6   \n",
      "24            99548.4   93984.3   98113.2   99857.7  110557.6  145145.8   \n",
      "\n",
      "Date_Id           7         8         9         10   ...       92        93   \\\n",
      "Hour_of_Day                                          ...                       \n",
      "1             99867.6  102279.3   71776.7   67342.3  ...   72604.3   51338.6   \n",
      "2             72209.7   71624.2   51151.5   51031.3  ...   51162.9   39750.0   \n",
      "3             62264.7       NaN   47625.0   48223.3  ...   40684.1   39328.1   \n",
      "4             58017.3   59332.2   65616.2   64376.9  ...   36183.9   54143.2   \n",
      "5             71566.7   56196.8  127818.7  123558.5  ...   40930.9  105968.5   \n",
      "6            108837.4   68266.7  236510.8  221979.1  ...   59438.1  202636.4   \n",
      "7            168972.1   97568.6  356901.4  356952.1  ...   85590.7  278751.4   \n",
      "8            234920.2  129913.8  455217.2  406024.3  ...  111329.9  315780.2   \n",
      "9            294821.0  178463.7  437688.9  453530.4  ...  142654.7  299403.5   \n",
      "10           344266.1  241179.2  367010.4  373526.4  ...  190006.8  286032.9   \n",
      "11           379922.9  299270.7  342709.6  336596.7  ...  232899.1  293367.4   \n",
      "12           406466.9  338886.7  345818.2       NaN  ...  270835.8  309189.2   \n",
      "13           420649.1  375381.4  360412.1  346921.6  ...  298139.2  327849.6   \n",
      "14           422043.9  391324.8  379107.4  367723.7  ...  309316.5  345052.5   \n",
      "15           423539.8  396938.0  423813.5  414635.2  ...  309425.1  376955.5   \n",
      "16           416903.3  395380.5  479647.8  460845.7  ...  299938.0  405866.9   \n",
      "17           406649.9  389568.0  504888.8  485810.8  ...  284915.3  412933.4   \n",
      "18           388878.3  369437.0  502474.6  485229.1  ...  277058.5  365111.3   \n",
      "19           350931.2  336897.5  386074.7  373938.4  ...  247550.2  247766.0   \n",
      "20           289426.8  305155.8  280508.6  271523.7  ...  209216.7  179459.4   \n",
      "21           243556.8  270326.2  221620.1  215105.9  ...  183676.2  139853.2   \n",
      "22           219543.3  217867.0  182508.9  177790.3  ...  146483.4  111477.1   \n",
      "23           194233.3  164509.2  139449.1  140068.1  ...  109715.0   89984.6   \n",
      "24           149639.6  109646.0   97662.6   96624.8  ...   75412.2   68230.7   \n",
      "\n",
      "Date_Id           94        95        96        97        98        99   \\\n",
      "Hour_of_Day                                                               \n",
      "1             49408.8   51072.1   53410.2   58735.3   70305.5   75722.5   \n",
      "2             40067.1   41047.3   42773.8   46105.3   51609.7   52895.3   \n",
      "3             39983.6   40902.5   42101.3   44462.4   44636.7   41647.2   \n",
      "4             53690.7   54957.7   56465.8   57183.1   44758.5   36681.0   \n",
      "5            103191.4  107730.7  108875.2  106298.6   60051.8   41084.6   \n",
      "6            198954.1  202231.9  204718.6  193724.4   94685.3   60187.8   \n",
      "7            284228.4  288234.7  289715.7  275185.5  138207.9   87267.6   \n",
      "8            321695.3  329328.7  327740.3  318464.6  181819.0  113886.3   \n",
      "9            301759.0  312049.5  312837.3  312075.6  220174.9  148356.9   \n",
      "10           285387.5  294802.8  296448.6  306349.4  262741.7  197659.8   \n",
      "11           287320.5  296536.4  300732.6  321092.6  302641.8  247435.4   \n",
      "12           297356.0  307622.3  312820.9  341729.4  333185.9  288275.7   \n",
      "13           315218.7  325036.7  329581.9  367051.9  349029.0  316064.8   \n",
      "14           329213.5  338341.1  344823.3  387701.1  354551.4  328935.3   \n",
      "15           363719.9  372584.4  379082.2  422902.8  356193.7  329648.7   \n",
      "16           391026.3  398855.9  410550.3  443612.9  342472.4  317639.9   \n",
      "17           392693.5  401602.5  411044.4  439475.2  323747.4  299297.3   \n",
      "18           360994.2  373169.8  387399.8  408079.6  296191.6  280981.9   \n",
      "19           255762.1  272082.2  291676.5  320888.5  261126.1  256993.0   \n",
      "20           182780.5  203779.1  218024.1  246405.3  225402.9  229507.0   \n",
      "21           144736.4  165902.4  177074.0  200825.4  198926.9  208128.2   \n",
      "22           114842.8  130448.3  144111.8  164992.1  175362.8  175959.5   \n",
      "23            92511.3  101336.3  113787.8  134352.4  149161.9  130133.7   \n",
      "24            69984.5   74373.0   83404.1  100794.9  110296.8   85764.2   \n",
      "\n",
      "Date_Id           100      101  \n",
      "Hour_of_Day                     \n",
      "1             56990.1  58068.2  \n",
      "2             42446.1      NaN  \n",
      "3             40760.2      NaN  \n",
      "4             54971.9      NaN  \n",
      "5            108952.9      NaN  \n",
      "6            207135.7      NaN  \n",
      "7            282264.6      NaN  \n",
      "8            323275.1      NaN  \n",
      "9            309439.1      NaN  \n",
      "10           293397.1      NaN  \n",
      "11           303623.4      NaN  \n",
      "12           319073.0      NaN  \n",
      "13           335616.1      NaN  \n",
      "14           351251.8      NaN  \n",
      "15           386622.8      NaN  \n",
      "16           414354.5      NaN  \n",
      "17           415766.5      NaN  \n",
      "18           390191.5      NaN  \n",
      "19           287675.8      NaN  \n",
      "20           212867.9      NaN  \n",
      "21           176569.7      NaN  \n",
      "22           147014.8      NaN  \n",
      "23           115242.9      NaN  \n",
      "24            83077.9      NaN  \n",
      "\n",
      "[24 rows x 101 columns]\n",
      "     Sensor_Data        Date  Hour_of_Day  Date_Id  Window_Id\n",
      "226          NaN  2020-03-10           12       10        NaN\n",
      "250          NaN  2020-03-11           12       11        NaN\n",
      "274          NaN  2020-03-12           12       12        NaN\n",
      "298          NaN  2020-03-13           12       13        NaN\n",
      "322          NaN  2020-03-14           12       14        NaN\n",
      "346          NaN  2020-03-15           12       15        NaN\n",
      "370          NaN  2020-03-16           12       16        NaN\n",
      "394          NaN  2020-03-17           12       17        NaN\n",
      "395          NaN  2020-03-17           13       17        NaN\n",
      "    Window_Id  Hour_of_Day  Date_Id  Sensor_Data        DateTime   Feature_1  \\\n",
      "0         1.0         12.0      1.0     365612.7  3/1/2020 11:00  22624991.0   \n",
      "1         1.0         12.0      2.0     359576.9  3/2/2020 11:00  21238681.8   \n",
      "2         1.0         12.0      3.0     353188.3  3/3/2020 11:00  20910562.5   \n",
      "3         1.0         12.0      4.0     356740.7  3/4/2020 11:00  21201236.7   \n",
      "4         1.0         12.0      5.0     370030.2  3/5/2020 11:00  21730051.4   \n",
      "..        ...          ...      ...          ...             ...         ...   \n",
      "69        2.0         13.0     33.0     254318.5  4/2/2020 12:00  15570664.4   \n",
      "70        2.0         13.0     34.0     279657.3  4/3/2020 12:00  17094740.0   \n",
      "71        2.0         13.0     35.0     233806.1  4/4/2020 12:00  14919809.6   \n",
      "72        2.0         13.0     36.0     187440.6  4/5/2020 12:00  12112496.1   \n",
      "73        2.0         13.0     37.0     240288.5  4/6/2020 12:00  14681794.1   \n",
      "\n",
      "    Feature_2  Actual_Data        Date  Forward_Impute  Backward_Impute  \n",
      "0    421212.0     365612.7  2020-03-01        365612.7         365612.7  \n",
      "1    421212.0     359576.9  2020-03-02        359576.9         359576.9  \n",
      "2    420696.0     353188.3  2020-03-03        353188.3         353188.3  \n",
      "3    420900.0     356740.7  2020-03-04        356740.7         356740.7  \n",
      "4    421044.0     370030.2  2020-03-05        370030.2         370030.2  \n",
      "..        ...          ...         ...             ...              ...  \n",
      "69   421680.0     254318.5  2020-04-02        254318.5         254318.5  \n",
      "70   421680.0     279657.3  2020-04-03        279657.3         279657.3  \n",
      "71   421622.0     233806.1  2020-04-04        233806.1         233806.1  \n",
      "72   421692.0     187440.6  2020-04-05        187440.6         187440.6  \n",
      "73   421692.0     240288.5  2020-04-06        240288.5         240288.5  \n",
      "\n",
      "[74 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-aba0b3d22ff1>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_missing[\"Window_Id\"] = np.nan\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "c:\\users\\gurud\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Assign K value here\n",
    "\n",
    "KNNImputation_value = 15\n",
    "\n",
    "# Reduce the dataset to use 100 days of the data\n",
    "df = df[:2400]\n",
    "\n",
    "# pick datetime and sensor data with missing values\n",
    "\n",
    "df_simplified = df[['DateTime', 'Sensor_Data']]\n",
    "\n",
    "# Split the datetime column into date column and hour column\n",
    "\n",
    "df_simplified.loc[:,\"Date\"] = pd.to_datetime(df_simplified['DateTime']).dt.date\n",
    "df_simplified.loc[:,\"Hour_of_Day\"] = pd.to_datetime(df_simplified['DateTime']).dt.strftime(\"%H\")\n",
    "df_simplified[\"Hour_of_Day\"] = pd.to_numeric(df_simplified[\"Hour_of_Day\"]) + 1\n",
    "\n",
    "# Generate a unique number for each date for simplicity of the program \n",
    "df_simplified.loc[:,\"Date_Id\"] = df_simplified.groupby(['Date'], sort=False).ngroup() + 1\n",
    "\n",
    "# Do the same for original table by making sure date and hour columns are separte we will use these columns\n",
    "# later for joining\n",
    "\n",
    "df.loc[:,\"Date\"] = pd.to_datetime(df['DateTime']).dt.date\n",
    "df.loc[:,\"Hour_of_Day\"] = pd.to_datetime(df['DateTime']).dt.strftime(\"%H\")\n",
    "df[\"Hour_of_Day\"] = pd.to_numeric(df[\"Hour_of_Day\"]) + 1\n",
    "df.loc[:,\"Date_Id\"] = df.groupby(['Date'], sort=False).ngroup() + 1\n",
    "\n",
    "# Now that we have split datetime into date and hour we will drop datetime column\n",
    "df_simplified = df_simplified.drop(['DateTime'],axis=1)\n",
    "\n",
    "# Pivot the table by transforming datetime row into column this way we have a new column for each date is generated for 24 hours of the day\n",
    "# so the values of each column represent sensor data for each hour\n",
    "df_pivot = df_simplified.pivot(index='Hour_of_Day', columns='Date_Id', values='Sensor_Data')\n",
    "print(df_pivot)\n",
    "# Filter all missing sensor data value into a separate data frameFind all missing values\n",
    "df_missing = df_simplified[df_simplified['Sensor_Data'].isna()] \n",
    "df_missing[\"Window_Id\"] = np.nan\n",
    "\n",
    "# We need to loop thru the each missing value and create window. Each window will have one or more missing values along with the sensor data \n",
    "# before and after the missing value(s). If number of missing values within in the window is less then or equal 5, we take 5 sensor values before and 5 sensor \n",
    "# values after the missing value(s). However, if there are more than 5 missing values for example if there are 10 missing values it will take \n",
    "# 10 values before and 10 values after the missing values(s).\n",
    "\n",
    "# min window imputing size is set to 5 as per above explaination\n",
    "min_window_imputing_size = 20\n",
    "\n",
    "# Create an empty data frame which will later be used to form windows\n",
    "df_windows = pd.DataFrame(columns=['Window_Id', 'Hour_of_Day', 'Date_Id', 'Sensor_Data'])\n",
    "window_id = 0\n",
    "print(df_missing)\n",
    "for index, row in df_missing.iterrows():\n",
    "    \n",
    "    col_index = row['Date_Id'] - 1\n",
    "    row_index = row['Hour_of_Day'] - 1\n",
    "   \n",
    "    # check if the previous missing value is NaN, this check will help add all consecutive missing values into one window. \n",
    "    # When previous missing value is NaN then it means a window is already build in the previous iteration\n",
    "    if (isNaN(df_pivot.iat[row_index,col_index-1])):\n",
    "        continue\n",
    "        \n",
    "    # check if current value is not null\n",
    "    #if(isNaN(df_pivot.iat[row_index,col_index]) == False):\n",
    "        #continue\n",
    "        \n",
    "    counter = 1\n",
    "    while True:\n",
    "        # In the pivot table check if the next day for same hour has a NaN values if it is then continue to loop to find total consecutive \n",
    "        # missing values else break\n",
    "        if(isNaN(df_pivot.iat[row_index,col_index + counter])):\n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # Find the total size of the window\n",
    "    no_of_imputation_in_gap = min_window_imputing_size if counter <= min_window_imputing_size else counter\n",
    "    \n",
    "    # Find window start index\n",
    "    start_index_of_window = (col_index - no_of_imputation_in_gap) if (col_index - no_of_imputation_in_gap) > 0 else 0       \n",
    "    \n",
    "    # Find window end index\n",
    "    end_index_of_window = (col_index + counter + no_of_imputation_in_gap) if (col_index + counter + no_of_imputation_in_gap) < (df_pivot.shape[1] -1) else df_pivot.shape[1] -1\n",
    "    \n",
    "    # From the pivot table, filter the data frame to fetch window which contains both missing values and sensor data to use for imputation  \n",
    "    ds_missing = df_pivot.iloc[row_index, start_index_of_window : end_index_of_window]\n",
    "    \n",
    "    # Update window column with a unique window id so later this column is used to filter to fetch window specific sensore data\n",
    "    window_id = window_id + 1\n",
    "    df_missing.loc[index, 'Window_Id'] = window_id\n",
    "    \n",
    "    # Create a new dataframe df_windows which holds all window data\n",
    "    for date_id, value in ds_missing.items():\n",
    "        df_windows = df_windows.append({'Window_Id': window_id, 'Hour_of_Day': row['Hour_of_Day'], 'Date_Id': date_id, 'Sensor_Data': value}, ignore_index=True)\n",
    "\n",
    "# Now that we have all the windows data in df_windows, next part of the code will loop thru each window to impute data\n",
    "\n",
    "# Create new dataframe df_merged which is an inner join of df_windows and original df dataframe to get some additional columns\n",
    "# Merge will rename the columns if both the merged dataframe has same column names and we need to correct them and drop additionals\n",
    "df_merged = pd.merge(df_windows, df, on=['Hour_of_Day', 'Date_Id'], how='inner')\n",
    "df_merged = df_merged.drop(['Sensor_Data_y'], axis=1)\n",
    "df_merged.rename(columns = {'Sensor_Data_x':'Sensor_Data'}, inplace = True)\n",
    "   \n",
    "# impute_column_name will hold the column name of the sensor data to impute\n",
    "impute_column_name = \"Sensor_Data\"\n",
    "\n",
    "# Create two new columns Forward_Impute, Backward_Impute which initially has same data as sensor data column but further these columns will \n",
    "# populate itself with the forward imputed and backward imputed values\n",
    "df_merged[\"Forward_Impute\"] = df_merged[impute_column_name]\n",
    "df_merged[\"Backward_Impute\"] = df_merged[impute_column_name]\n",
    "\n",
    "print(df_merged)\n",
    "# Loop each window\n",
    "for i in range(1,window_id + 1):\n",
    "   \n",
    "    # Filter data specific to the window, this wil fetch all the records of a specific window which includes both NaN and sensor data before \n",
    "    # and after gap\n",
    "    df_window = df_merged[df_merged['Window_Id'] == i]\n",
    "    # Since the df_window now has filter records, its index column of dataframe will not be ordinal, reset will help get is reordered\n",
    "    df_window.reset_index(drop=True, inplace=True)\n",
    "   \n",
    "    # declare some variables to used in the inner loop\n",
    "    \n",
    "    # Hour of the day\n",
    "    window_hour = df_window['Hour_of_Day'].values[0]\n",
    "    \n",
    "    # First Date Id of the window\n",
    "    first_date_id = df_window['Date_Id'].values[0]\n",
    "  \n",
    "    # Last Date Id of the window\n",
    "    last_date_id = df_window['Date_Id'].values[-1]\n",
    "    \n",
    "    # Find the first occurrence of NaN in the window\n",
    "    first_missing_occurrence_date_id = 0\n",
    "    for index, row in df_window.iterrows():\n",
    "        if(isNaN(row[impute_column_name])):\n",
    "            first_missing_occurrence_date_id = row[\"Date_Id\"]\n",
    "            break;\n",
    "        else:\n",
    "            continue;\n",
    "        \n",
    "    # Find total missing values\n",
    "    total_missing_values = df_window[impute_column_name].isna().sum()\n",
    "    \n",
    "    # Last missing occurance of NaN\n",
    "    last_missing_occurrence_date_id = first_missing_occurrence_date_id + total_missing_values - 1\n",
    "    \n",
    "    \n",
    "    # Forward Imputation - Loop for the sliding window for Forward imputation and populate the imputed values into \"Forward_Impute\" column\n",
    "    for j in range(0,total_missing_values):\n",
    "        \n",
    "        # filter to fetch the sliding window from the main window. \n",
    "        # Sliding window in the forward impute will start from the begining and impute one missing value at a time so each sliding window\n",
    "        # will have a missing sensor value at the end of the window\n",
    "        df_window_subset = df_window[(df_window['Date_Id'] >= (first_date_id + j)) & (df_window['Date_Id'] <= (first_missing_occurrence_date_id + j))]\n",
    "        cols = ['Date_Id','Forward_Impute', 'Feature_1', 'Feature_2']\n",
    "        \n",
    "        # From the sliding window, create a new dataframe to be used by KNN algorithm which requires feature columns and no Nan values in \n",
    "        # the data. So those are replaced by 0\n",
    "        df_knn_window_subset = df_window_subset[cols].copy()\n",
    "        df_knn_window_subset[cols] = df_knn_window_subset[cols].fillna(0).astype(int)\n",
    "        df_knn_window_subset[cols] = df_knn_window_subset[cols].replace({'0':np.nan, 0:np.nan})\n",
    "        \n",
    "        # Perform KNN imputation on the resultant dataframe \"df_knn_window_subset\"\n",
    "        # Define imputer\n",
    "        imputer = KNNImputer(n_neighbors=KNNImputation_value, weights='uniform', metric='nan_euclidean')\n",
    "        # fit on the dataset\n",
    "        imputer.fit(df_knn_window_subset)\n",
    "        # transform the dataset\n",
    "        df_knn_window_subset_transformed = imputer.transform(df_knn_window_subset)\n",
    "        df_result = pd.DataFrame(df_knn_window_subset_transformed, columns =cols)\n",
    "        \n",
    "        # Retrieve the imputed value from resultant data frame and update df_window\n",
    "        # Missing row index\n",
    "        missing_row_index = first_missing_occurrence_date_id - first_date_id\n",
    "        df_window.at[missing_row_index+j, 'Forward_Impute'] = df_result.at[missing_row_index,\"Forward_Impute\"]\n",
    "        j=j+1\n",
    "    \n",
    "    \n",
    "    # Backward Imputation - Loop for the sliding window for Forward imputation and populate the imputed values into \"Backward_Impute\" column    \n",
    "    for j in range(0,total_missing_values):\n",
    "        \n",
    "        # filter to fetch the sliding window from the main window. \n",
    "        # Sliding window in the backward impute will start from the end and impute one missing value at a time to the center so each sliding window\n",
    "        # will have a missing sensor value at the begining of the window\n",
    "        df_window_subset = df_window[(df_window['Date_Id'] <= (last_date_id - j)) & (df_window['Date_Id'] >= (last_missing_occurrence_date_id - j))]\n",
    "        cols = ['Date_Id','Backward_Impute', 'Feature_1', 'Feature_2']\n",
    "        df_knn_window_subset = df_window_subset[cols].copy()  \n",
    "        df_knn_window_subset[cols] = df_knn_window_subset[cols].fillna(0).astype(int)\n",
    "        df_knn_window_subset[cols] = df_knn_window_subset[cols].replace({'0':np.nan, 0:np.nan})\n",
    "        \n",
    "        # Perform KNN imputation on the resultant dataframe \"df_knn_window_subset\"\n",
    "        # Define imputer\n",
    "        imputer = KNNImputer(n_neighbors=KNNImputation_value, weights='uniform', metric='nan_euclidean')\n",
    "        # fit on the dataset\n",
    "        imputer.fit(df_knn_window_subset)\n",
    "        # transform the dataset\n",
    "        df_knn_window_subset_transformed = imputer.transform(df_knn_window_subset)\n",
    "        df_result = pd.DataFrame(df_knn_window_subset_transformed, columns =cols)\n",
    "        \n",
    "        # Retrieve the imputed value from result data frame and update df_window\n",
    "        # Missing row index\n",
    "        missing_row_index = 0\n",
    "        df_window.at[last_missing_occurrence_date_id-first_date_id - j, 'Backward_Impute'] = df_result.at[missing_row_index,\"Backward_Impute\"]\n",
    "        \n",
    "\n",
    "    # After forward and backward sliding, we will have columns \"Forward_Impute\", Backward_Impute\" populated with imputed values\n",
    "    # Now merge those values into df_merged table\n",
    "    df_merged = pd.merge(df_merged, df_window, on=['Hour_of_Day', 'Date_Id'], how='left')\n",
    "    df_merged['Backward_Impute_x'] = df_merged['Backward_Impute_y'].fillna(df_merged['Backward_Impute_x'])\n",
    "    df_merged['Forward_Impute_x'] = df_merged['Forward_Impute_y'].fillna(df_merged['Forward_Impute_x'])\n",
    "    drop_cols = ['Window_Id_y', 'Sensor_Data_y', 'DateTime_y', 'Feature_1_y', 'Feature_2_y', 'Date_y', 'Forward_Impute_y', 'Backward_Impute_y']\n",
    "    df_merged = df_merged.drop(drop_cols, axis=1)    \n",
    "    # Rename columns created with merge\n",
    "    df_merged.rename(columns = {'Window_Id_x':'Window_Id', 'Sensor_Data_x':'Sensor_Data', 'DateTime_x':'DateTime', 'Feature_1_x':'Feature_1','Feature_2_x':'Feature_2', 'Date_x':'Date', 'Forward_Impute_x':'Forward_Impute', 'Backward_Impute_x':'Backward_Impute'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Window_Id  Hour_of_Day  Date_Id  Sensor_Data        DateTime   Feature_1  \\\n",
      "0         1.0         12.0      1.0     365612.7  3/1/2020 11:00  22624991.0   \n",
      "1         1.0         12.0      2.0     359576.9  3/2/2020 11:00  21238681.8   \n",
      "2         1.0         12.0      3.0     353188.3  3/3/2020 11:00  20910562.5   \n",
      "3         1.0         12.0      4.0     356740.7  3/4/2020 11:00  21201236.7   \n",
      "4         1.0         12.0      5.0     370030.2  3/5/2020 11:00  21730051.4   \n",
      "..        ...          ...      ...          ...             ...         ...   \n",
      "69        2.0         13.0     33.0     254318.5  4/2/2020 12:00  15570664.4   \n",
      "70        2.0         13.0     34.0     279657.3  4/3/2020 12:00  17094740.0   \n",
      "71        2.0         13.0     35.0     233806.1  4/4/2020 12:00  14919809.6   \n",
      "72        2.0         13.0     36.0     187440.6  4/5/2020 12:00  12112496.1   \n",
      "73        2.0         13.0     37.0     240288.5  4/6/2020 12:00  14681794.1   \n",
      "\n",
      "    Feature_2  Actual_Data_x_x        Date  Forward_Impute  Backward_Impute  \\\n",
      "0    421212.0         365612.7  2020-03-01        365612.7         365612.7   \n",
      "1    421212.0         359576.9  2020-03-02        359576.9         359576.9   \n",
      "2    420696.0         353188.3  2020-03-03        353188.3         353188.3   \n",
      "3    420900.0         356740.7  2020-03-04        356740.7         356740.7   \n",
      "4    421044.0         370030.2  2020-03-05        370030.2         370030.2   \n",
      "..        ...              ...         ...             ...              ...   \n",
      "69   421680.0         254318.5  2020-04-02        254318.5         254318.5   \n",
      "70   421680.0         279657.3  2020-04-03        279657.3         279657.3   \n",
      "71   421622.0         233806.1  2020-04-04        233806.1         233806.1   \n",
      "72   421692.0         187440.6  2020-04-05        187440.6         187440.6   \n",
      "73   421692.0         240288.5  2020-04-06        240288.5         240288.5   \n",
      "\n",
      "    Actual_Data_y_x  Actual_Data_x_y  Actual_Data_y_y  Transform_Prediction  \\\n",
      "0          365612.7              NaN              NaN                   0.0   \n",
      "1          359576.9              NaN              NaN                   0.0   \n",
      "2          353188.3              NaN              NaN                   0.0   \n",
      "3          356740.7              NaN              NaN                   0.0   \n",
      "4          370030.2              NaN              NaN                   0.0   \n",
      "..              ...              ...              ...                   ...   \n",
      "69              NaN         254318.5              NaN                   0.0   \n",
      "70              NaN         279657.3              NaN                   0.0   \n",
      "71              NaN         233806.1              NaN                   0.0   \n",
      "72              NaN         187440.6              NaN                   0.0   \n",
      "73              NaN         240288.5              NaN                   0.0   \n",
      "\n",
      "    Prediction  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "..         ...  \n",
      "69         0.0  \n",
      "70         0.0  \n",
      "71         0.0  \n",
      "72         0.0  \n",
      "73         0.0  \n",
      "\n",
      "[74 rows x 16 columns]\n",
      "R2 Score:\n",
      "-0.09886498781703001\n",
      "\n",
      " Root Mean Square Error:\n",
      "31950.388621536804\n",
      "\n",
      " MAE:\n",
      "27721.892592592587\n",
      "    Actual_Data  Prediction\n",
      "9        332696      311975\n",
      "10       340207      311398\n",
      "11       361926      311149\n",
      "12       367195      311394\n",
      "13       329703      312219\n",
      "14       277620      311502\n",
      "15       306692      309485\n",
      "16       285007      306215\n",
      "53       296572      314596\n",
      "    Forward_Impute  Backward_Impute  Sensor_Data  Prediction     Prediction\n",
      "0    365612.700000    365612.700000     365612.7         NaN       0.000000\n",
      "1    359576.900000    359576.900000     359576.9         NaN       0.000000\n",
      "2    353188.300000    353188.300000     353188.3         NaN       0.000000\n",
      "3    356740.700000    356740.700000     356740.7         NaN       0.000000\n",
      "4    370030.200000    370030.200000     370030.2         NaN       0.000000\n",
      "5    394238.300000    394238.300000     394238.3         NaN       0.000000\n",
      "6    406466.900000    406466.900000     406466.9         NaN       0.000000\n",
      "7    338886.700000    338886.700000     338886.7         NaN       0.000000\n",
      "8    345818.200000    345818.200000     345818.2         NaN       0.000000\n",
      "9    365617.111111    258334.866667          NaN    311975.0  311975.988889\n",
      "10   365617.666667    257180.066667          NaN    311398.0  311398.866667\n",
      "11   366288.888889    256010.933333          NaN    311149.0  311149.911111\n",
      "12   367744.444444    255043.600000          NaN    311394.0  311394.022222\n",
      "13   368967.111111    255471.800000          NaN    312219.0  312219.455556\n",
      "14   368849.000000    254156.733333          NaN    311502.0  311502.866667\n",
      "15   366028.000000    252942.133333          NaN    309485.0  309485.066667\n",
      "16   361534.888889    250895.733333          NaN    306215.0  306215.311111\n",
      "17   275798.400000    275798.400000     275798.4         NaN       0.000000\n",
      "18   277695.500000    277695.500000     277695.5         NaN       0.000000\n",
      "19   289211.000000    289211.000000     289211.0         NaN       0.000000\n",
      "20   247858.900000    247858.900000     247858.9         NaN       0.000000\n",
      "21   199965.200000    199965.200000     199965.2         NaN       0.000000\n",
      "22   243937.900000    243937.900000     243937.9         NaN       0.000000\n",
      "23   234723.100000    234723.100000     234723.1         NaN       0.000000\n",
      "24   256767.600000    256767.600000     256767.6         NaN       0.000000\n",
      "25   242415.700000    242415.700000     242415.7         NaN       0.000000\n",
      "26   259645.900000    259645.900000     259645.9         NaN       0.000000\n",
      "27   220236.500000    220236.500000     220236.5         NaN       0.000000\n",
      "28   179453.800000    179453.800000     179453.8         NaN       0.000000\n",
      "29   239858.900000    239858.900000     239858.9         NaN       0.000000\n",
      "30   234430.100000    234430.100000     234430.1         NaN       0.000000\n",
      "31   238473.400000    238473.400000     238473.4         NaN       0.000000\n",
      "32   240533.800000    240533.800000     240533.8         NaN       0.000000\n",
      "33   261894.800000    261894.800000     261894.8         NaN       0.000000\n",
      "34   220199.900000    220199.900000     220199.9         NaN       0.000000\n",
      "35   167136.400000    167136.400000     167136.4         NaN       0.000000\n",
      "36   224282.500000    224282.500000     224282.5         NaN       0.000000\n",
      "37   390616.200000    390616.200000     390616.2         NaN       0.000000\n",
      "38   366849.200000    366849.200000     366849.2         NaN       0.000000\n",
      "39   362787.000000    362787.000000     362787.0         NaN       0.000000\n",
      "40   366784.200000    366784.200000     366784.2         NaN       0.000000\n",
      "41   378460.800000    378460.800000     378460.8         NaN       0.000000\n",
      "42   421637.200000    421637.200000     421637.2         NaN       0.000000\n",
      "43   420649.100000    420649.100000     420649.1         NaN       0.000000\n",
      "44   375381.400000    375381.400000     375381.4         NaN       0.000000\n",
      "45   360412.100000    360412.100000     360412.1         NaN       0.000000\n",
      "46   346921.600000    346921.600000     346921.6         NaN       0.000000\n",
      "47   354154.400000    354154.400000     354154.4         NaN       0.000000\n",
      "48   386765.200000    386765.200000     386765.2         NaN       0.000000\n",
      "49   388801.000000    388801.000000     388801.0         NaN       0.000000\n",
      "50   341748.300000    341748.300000     341748.3         NaN       0.000000\n",
      "51   302461.400000    302461.400000     302461.4         NaN       0.000000\n",
      "52   320903.900000    320903.900000     320903.9         NaN       0.000000\n",
      "53   364311.933333    264880.933333          NaN    314596.0  314596.433333\n",
      "54   288733.800000    288733.800000     288733.8         NaN       0.000000\n",
      "55   290553.200000    290553.200000     290553.2         NaN       0.000000\n",
      "56   307614.500000    307614.500000     307614.5         NaN       0.000000\n",
      "57   262244.100000    262244.100000     262244.1         NaN       0.000000\n",
      "58   219359.700000    219359.700000     219359.7         NaN       0.000000\n",
      "59   255007.400000    255007.400000     255007.4         NaN       0.000000\n",
      "60   246764.100000    246764.100000     246764.1         NaN       0.000000\n",
      "61   267736.100000    267736.100000     267736.1         NaN       0.000000\n",
      "62   255797.000000    255797.000000     255797.0         NaN       0.000000\n",
      "63   278138.600000    278138.600000     278138.6         NaN       0.000000\n",
      "64   234279.500000    234279.500000     234279.5         NaN       0.000000\n",
      "65   198748.100000    198748.100000     198748.1         NaN       0.000000\n",
      "66   253613.200000    253613.200000     253613.2         NaN       0.000000\n",
      "67   246990.800000    246990.800000     246990.8         NaN       0.000000\n",
      "68   252244.700000    252244.700000     252244.7         NaN       0.000000\n",
      "69   254318.500000    254318.500000     254318.5         NaN       0.000000\n",
      "70   279657.300000    279657.300000     279657.3         NaN       0.000000\n",
      "71   233806.100000    233806.100000     233806.1         NaN       0.000000\n",
      "72   187440.600000    187440.600000     187440.6         NaN       0.000000\n",
      "73   240288.500000    240288.500000     240288.5         NaN       0.000000\n"
     ]
    }
   ],
   "source": [
    "# \"Forward_Impute\", \"Backward_Impute\" are further averaged into \"Prediction\" column\n",
    "\n",
    "print(df_merged)\n",
    "\n",
    "df_merged_actual= pd.merge(df_merged,df[['DateTime','Actual_Data']],on='DateTime', how='inner')\n",
    "df_merged[\"Transform_Prediction\"] = df_merged[\"Sensor_Data\"].apply(lambda x: x if x!=x else 0)\n",
    "df_merged['Prediction'] = df_merged[\"Transform_Prediction\"].fillna((df_merged['Forward_Impute'] + df_merged['Backward_Impute'])/2)\n",
    "df_merged_actual['Actual_Data'] = df_merged[\"Transform_Prediction\"].fillna(df_merged_actual['Actual_Data'])\n",
    "\n",
    "\n",
    "# Acutal data and Predictions columns are concatenated into df_Results\n",
    "y_true = df_merged_actual[df_merged_actual['Actual_Data'] != 0]['Actual_Data']\n",
    "y_pred = df_merged[df_merged['Prediction'] != 0]['Prediction']\n",
    "\n",
    "\n",
    "# Calculate R2 score\n",
    "\n",
    "print(\"R2 Score:\")\n",
    "print(r2_score(y_true, y_pred))\n",
    "\n",
    "# Calculate RMSE\n",
    "\n",
    "MSE = np.square(np.subtract(y_true,y_pred)).mean() \n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"\\n Root Mean Square Error:\")\n",
    "print(RMSE)\n",
    "\n",
    "# Calculate MAE\n",
    "\n",
    "print(\"\\n MAE:\")\n",
    "MAE = mean_absolute_error(y_true, y_pred)\n",
    "print(MAE)\n",
    "\n",
    "# Concatenating all the results\n",
    "df_Results = pd.concat([y_true, y_pred], axis=1).astype(int)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df_Results)\n",
    "    \n",
    "# All columns\n",
    "df_all_result = pd.concat([df_Results, df_merged], axis=1)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df_all_result[['Forward_Impute', 'Backward_Impute', 'Sensor_Data', 'Prediction']])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
